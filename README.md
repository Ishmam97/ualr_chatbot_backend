# UALR Chatbot Backend

A FastAPI service powering the UALR Chatbot, retrieving documents via FAISS + Google Gemini embeddings and serving a `/query` and `/feedback` API.

---

## ğŸ·ï¸ Project Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ **init**.py
â”‚   â”œâ”€â”€ main.py            # FastAPI app entrypoint&#x20;
â”‚   â”œâ”€â”€ retriever.py       # FAISS-based document retriever&#x20;
â”‚   â””â”€â”€ llm.py             # LLM invocation helpers (Gemini/Ollama)&#x20;
â”œâ”€â”€ faiss\_index.index      # Precomputed FAISS index (binary)
â”œâ”€â”€ doc\_metadata.pkl       # Pickled metadata for indexed docs
â”œâ”€â”€ feedback\_log.jsonl     # Local store for user feedback
â”œâ”€â”€ Dockerfile             # Production image build recipe&#x20;
â”œâ”€â”€ docker-compose.yml     # Dev compose setup (hot-reload)&#x20;
â”œâ”€â”€ pyproject.toml         # Poetry dependencies & configuration
â””â”€â”€ README.md              # â† You are here

````

---

## ğŸš€ Prerequisites

- **Docker** & **Docker Compose**  
- **Poetry** (for local installs, optional)  
- A Google GenAI API key for embeddings & chat (set `LANGSMITH_API_KEY` / `GOOGLE_API_KEY` env var)

---

## ğŸ”§ Environment Variables

Create a `.env` file in the project root:

```env
PORT=8000
````

These will be picked up by both Docker Compose and the application.

---

## ğŸ³ Development with Docker Compose

We mount your local code into the container and use Uvicornâ€™s `--reload` for instant hot-reloading:

```bash
# First time (or after pyproject/poetry.lock changes):
docker-compose up --build

# Subsequent code edits:
# Uvicorn will auto-reload; just save files and refresh your HTTP client

# Teardown:
docker-compose down
```

* **API endpoints**

  * `POST /query`  â†’ run a search & LLM roundtrip
  * `POST /feedback` â†’ store user feedback locally & to LangSmith
  * `GET  /health` â†’ simple health check

---

## ğŸ”¨ Manual Docker Build & Run (OPTIONAL)

If you prefer plain Docker:

```bash
# 1. Build image
docker build -t ualr-chatbot-backend:latest .

# 2. Run (detached)
docker run -d \
  --name ualr-backend \
  --env-file .env \
  -p 8000:8000 \
  ualr-chatbot-backend:latest \
  uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 1

# 3. Check logs
docker logs -f ualr-backend

# 4. Health-check
curl http://localhost:8000/health
```

---

## ğŸ§ª Testing

```bash
# Install dev deps locally (optional)
poetry install --with dev

# Run pytest
pytest
```

---

## ğŸ“¦ Production Deployment

* Render (or your target host) will use the **Dockerfile** and its `CMD` to build & run.
* No need to push `docker-compose.yml` or `.env`â€”just ensure your Dockerfile and start command in Render match `app.main:app`.

---

## â“ Troubleshooting

* **Module import errors** â†’ ensure you run `uvicorn app.main:app` (not `main:app`).
* **Port conflicts** â†’ adjust `PORT` in `.env` and host mapping.
* **Missing keys** â†’ verify `LANGSMITH_API_KEY` / `GOOGLE_API_KEY` are set.

---

Happy coding! ğŸš€
